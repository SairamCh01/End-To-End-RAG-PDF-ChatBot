# AI RAG PDF Chatbot with FastAPI, ChromaDB & Streamlit

This project is a modular **Retrieval-Augmented Generation (RAG)** application that allows users to upload PDF documents and chat with an AI assistant that answers queries based on the document content. It features a microservice architecture with a decoupled **FastAPI backend** and **Streamlit frontend**, using **ChromaDB** as the vector store and **Groq's LLaMA3 model** as the LLM.

## ğŸ“‚ Project Structure

```
ragbot2.0/
â”œâ”€â”€ client/         # Streamlit Frontend
â”‚   |â”€â”€components/
|   |  |â”€â”€chatUI.py
|   |  |â”€â”€history_download.py
|   |  |â”€â”€upload.py
|   |â”€â”€utils/
|   |  |â”€â”€api.py
|   |â”€â”€app.py
|   |â”€â”€config.py
â”œâ”€â”€ server/         # FastAPI Backend
â”‚   â”œâ”€â”€ chroma_store/ ....after run
|   |â”€â”€modules/
â”‚      â”œâ”€â”€ load_vectorestore.py
â”‚      â”œâ”€â”€ llm.py
â”‚      â”œâ”€â”€ pdf_handler.py
â”‚      â”œâ”€â”€ query_handlers.py
|   |â”€â”€uploaded_pdfs/ ....after run
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ main.py
â””â”€â”€ README.md
```

## Features

-  Upload and parse PDFs
-  Embed document chunks with HuggingFace embeddings
-  Store embeddings in ChromaDB
-  Query documents using LLaMA3 via Groq
-  Microservice architecture (Streamlit client + FastAPI server)

##  How RAG Works

Retrieval-Augmented Generation (RAG) enhances LLMs by injecting external knowledge. Instead of relying solely on pre-trained data, the model retrieves relevant information from a vector database (like ChromaDB) and uses it to generate accurate, context-aware responses.

## Application Diagram

ğŸ“„ [Download the Full Architecture PDF](RagBot_Architecture.pdf)

##  Getting Started Locally

### 1. Clone the Repository

```bash
git clone https://github.com/snsupratim/ragbot.git
cd ragbot
```

### 2. Setup the Backend (FastAPI)

```bash
cd server
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Set your Groq API Key
echo "GROQ_API_KEY=your_key_here" > .env

# Run the FastAPI server
uvicorn main:app --reload
```

### 3. Setup the Frontend (Streamlit)

```bash
cd ../client
pip install -r requirements.txt  # if you use a separate venv for client
streamlit run app.py
```

##  API Endpoints (FastAPI)

- `POST /upload_pdfs/` â€” Upload PDFs and build vectorstore
- `POST /ask/` â€” Send a query and receive answers

Testable via Postman or directly from the Streamlit frontend.

## Credits

- [LangChain](https://www.langchain.com/)
- [ChromaDB](https://www.trychroma.com/)
- [Groq](https://groq.com/)
- [Streamlit](https://streamlit.io/)


> Happy Building RAGbots! ğŸš€
